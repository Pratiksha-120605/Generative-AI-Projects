# ğŸ“„ RAG Document Q&A System using Groq + Llama3

A Retrieval-Augmented Generation (RAG) based Document Question-Answering System built using Groq API, Llama3, LangChain, FAISS, Ollama Embeddings, and Streamlit.

This project allows users to ask questions from research papers (PDFs) stored locally and generates accurate, context-aware responses using vector similarity search and large language models.

---

## ğŸš€ Features

- ğŸ“‚ Load multiple PDF documents from a folder
- âœ‚ï¸ Automatic document chunking
- ğŸ” Vector similarity search using FAISS
- ğŸ§  Context-aware answering with Llama3 (Groq API)
- âš¡ High-speed inference using Groq
- ğŸ¨ Clean and interactive Streamlit UI
- ğŸ“š View retrieved document chunks for transparency
- ğŸ§© Modular and easy-to-extend architecture

---

## ğŸ—ï¸ Architecture Flow

User Question  
â†’ Document Embedding  
â†’ FAISS Vector Store  
â†’ Similarity Search  
â†’ Context Retrieval  
â†’ Llama3 via Groq  
â†’ Final Answer  

---

## ğŸ›  Tech Stack

- Python
- Streamlit
- LangChain
- Groq API
- Llama3 (llama3-8b-8192)
- FAISS (Vector Database)
- Ollama Embeddings
- python-dotenv

---

## ğŸ“‚ Project Structure
```
rag-document-qa-groq-llama3/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ research_papers/
â”œâ”€â”€ paper1.pdf
â”œâ”€â”€ paper2.pdf
```

### ğŸ§  How It Works

- PDFs are loaded from the research_papers folder.

- Documents are split into smaller chunks.

- Each chunk is converted into embeddings using Ollama.

- Embeddings are stored in FAISS vector database.

- User asks a question.

- Relevant document chunks are retrieved using similarity search.

- Llama3 (via Groq API) generates an accurate answer using retrieved context.
-----------------------
## ğŸ“Œ Key Concepts Demonstrated

- Retrieval-Augmented Generation (RAG)

- Vector Databases (FAISS)

- Local Embeddings with Ollama

- Groq API integration

- Prompt Engineering

- Streamlit-based AI Application Development

## ğŸ’¡ Future Improvements

- PDF Upload feature from UI

- Chat history with memory

- Streaming responses

- Hybrid search (keyword + vector)

- Deployment on cloud (Render / AWS / GCP)

## ğŸ‘©â€ğŸ’» Author

Built as part of hands-on Generative AI learning and experimentation.  
